{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea2b3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n",
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca07725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ LOADING ALL MAIN DATASETS...\n",
      "üìà Loading Actual Sugar data...\n",
      "‚úÖ Sugar data: 15797 records\n",
      "üõ¢Ô∏è Loading Crude Oil data...\n",
      "‚úÖ Crude Oil data: 6549 records\n",
      "üí± Loading Exchange Rate data...\n",
      "‚úÖ Exchange Rate data: 5471 records\n",
      "üßä Loading ICE NY11 data...\n",
      "üìã ICE DataFrame columns: ['Date', 'Close', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "‚úÖ ICE data loaded: 6427 records\n",
      "\n",
      "üîπ Merging all datasets...\n",
      "Main data shape before ICE merge: (5330, 7)\n",
      "Overlapping dates with ICE: 5318\n",
      "‚úÖ Merged with real ICE data | Final shape: (5318, 9)\n",
      "\n",
      "‚úÖ Final dataset ready | Shape: (5318, 9)\n",
      "Columns: ['SUGAR', 'Crude_Oil_Price', 'USD_to_USD', 'BRL_to_USD', 'THB_to_USD', 'INR_to_USD', 'MYR_to_USD', 'ICE11_Price', 'ICE11_Synthetic']\n",
      "Date range: 2004-01-05 00:00:00 to 2025-10-07 00:00:00\n",
      "SUGAR price range: $0.0622 - $0.3965\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ LOAD AND MERGE MAIN DATASETS (RUN THIS FIRST)\n",
    "# ======================================================\n",
    "\n",
    "print(\"üîπ LOADING ALL MAIN DATASETS...\")\n",
    "\n",
    "# --- 1. Actual Sugar Data ---\n",
    "print(\"üìà Loading Actual Sugar data...\")\n",
    "sugar_df = pd.read_csv(r\"C:\\Users\\ramhya.kathirayson\\Downloads\\sugardata.csv\")\n",
    "sugar_df['Date'] = pd.to_datetime(sugar_df['Date'], errors='coerce')\n",
    "sugar_df.dropna(subset=['Date'], inplace=True)\n",
    "sugar_df = sugar_df[['Date', 'Value']].rename(columns={'Value': 'SUGAR'})\n",
    "sugar_df['SUGAR'] = pd.to_numeric(sugar_df['SUGAR'], errors='coerce')\n",
    "sugar_df.dropna(subset=['SUGAR'], inplace=True)\n",
    "sugar_df.set_index('Date', inplace=True)\n",
    "print(f\"‚úÖ Sugar data: {len(sugar_df)} records\")\n",
    "\n",
    "# --- 2. Crude Oil Data ---\n",
    "print(\"üõ¢Ô∏è Loading Crude Oil data...\")\n",
    "crude_df = pd.read_excel(r\"C:\\Users\\ramhya.kathirayson\\Downloads\\crudeoildata.xlsx\")\n",
    "crude_df['Date'] = pd.to_datetime(crude_df['Date'], errors='coerce')\n",
    "crude_df = crude_df[['Date', 'Price']].rename(columns={'Price': 'Crude_Oil_Price'})\n",
    "crude_df.dropna(subset=['Date', 'Crude_Oil_Price'], inplace=True)\n",
    "print(f\"‚úÖ Crude Oil data: {len(crude_df)} records\")\n",
    "\n",
    "# --- 3. Exchange Rate Data ---\n",
    "print(\"üí± Loading Exchange Rate data...\")\n",
    "fx = pd.read_csv(r\"C:\\Users\\ramhya.kathirayson\\Downloads\\exchange_rate_to_usd.csv\")\n",
    "fx['date'] = pd.to_datetime(fx['date'], errors='coerce')\n",
    "fx = fx[['date', 'us_dollar_to_usd', 'brazilian_real_to_usd', 'thai_baht_to_usd',\n",
    "         'indian_rupee_to_usd', 'malaysian_ringgit_to_usd']]\n",
    "fx.columns = ['Date', 'USD_to_USD', 'BRL_to_USD', 'THB_to_USD', 'INR_to_USD', 'MYR_to_USD']\n",
    "fx = fx.ffill().bfill()\n",
    "print(f\"‚úÖ Exchange Rate data: {len(fx)} records\")\n",
    "\n",
    "# --- 4. ICE NY11 Data ---\n",
    "print(\"üßä Loading ICE NY11 data...\")\n",
    "\n",
    "def load_daily_ice_data(ice_file_path):\n",
    "    \"\"\"Load and clean ICE NY11 daily data\"\"\"\n",
    "    try:\n",
    "        ice_df = pd.read_csv(ice_file_path)\n",
    "        print(\"üìã ICE DataFrame columns:\", ice_df.columns.tolist())\n",
    "        \n",
    "        if 'Date' not in ice_df.columns or 'Close' not in ice_df.columns:\n",
    "            raise ValueError(\"‚ùå ICE data must have 'Date' and 'Close' columns\")\n",
    "        \n",
    "        ice_df['Date'] = pd.to_datetime(ice_df['Date'], format='%b %d, %Y', errors='coerce')\n",
    "        ice_df.dropna(subset=['Date'], inplace=True)\n",
    "        \n",
    "        ice_df['Close'] = pd.to_numeric(ice_df['Close'], errors='coerce')\n",
    "        ice_df = ice_df.dropna(subset=['Close'])\n",
    "        \n",
    "        ice_clean = ice_df[['Date', 'Close']].rename(columns={'Close': 'ICE11_Price'})\n",
    "        print(f\"‚úÖ ICE data loaded: {len(ice_clean)} records\")\n",
    "        return ice_clean\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading ICE data: {e}\")\n",
    "        return None\n",
    "\n",
    "ice_df = load_daily_ice_data(r\"C:\\Users\\ramhya.kathirayson\\Downloads\\ICE_Data.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# üîπ MERGE ALL DATASETS\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüîπ Merging all datasets...\")\n",
    "merged_main = (\n",
    "    sugar_df.reset_index()\n",
    "    .merge(crude_df, on='Date', how='inner')\n",
    "    .merge(fx, on='Date', how='inner')\n",
    ")\n",
    "merged_main.set_index('Date', inplace=True)\n",
    "\n",
    "print(f\"Main data shape before ICE merge: {merged_main.shape}\")\n",
    "\n",
    "if ice_df is not None:\n",
    "    ice_df_indexed = ice_df.set_index('Date')\n",
    "    overlap = merged_main.index.intersection(ice_df_indexed.index)\n",
    "    print(f\"Overlapping dates with ICE: {len(overlap)}\")\n",
    "\n",
    "    if len(overlap) > 0:\n",
    "        df = merged_main.merge(ice_df_indexed[['ICE11_Price']], left_index=True, right_index=True, how='inner')\n",
    "        df['ICE11_Synthetic'] = False\n",
    "        print(f\"‚úÖ Merged with real ICE data | Final shape: {df.shape}\")\n",
    "    else:\n",
    "        # Synthetic ICE data fallback\n",
    "        np.random.seed(42)\n",
    "        merged_main['ICE11_Price'] = merged_main['SUGAR'] * np.random.uniform(0.95, 1.05, len(merged_main))\n",
    "        merged_main['ICE11_Synthetic'] = True\n",
    "        df = merged_main\n",
    "        print(\"‚ö†Ô∏è No overlap ‚Äî synthetic ICE data created\")\n",
    "else:\n",
    "    df = merged_main\n",
    "    df['ICE11_Synthetic'] = True\n",
    "    print(\"‚ö†Ô∏è Proceeding without ICE data\")\n",
    "\n",
    "# Final cleaning\n",
    "df = df.sort_index().dropna()\n",
    "print(f\"\\n‚úÖ Final dataset ready | Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"SUGAR price range: ${df['SUGAR'].min():.4f} - ${df['SUGAR'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884f92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(df, target_col='SUGAR', sequence_length=60, test_size=0.2):\n",
    "    \"\"\"Prepare data for LSTM\"\"\"\n",
    "    # Separate features and target\n",
    "    feature_columns = [col for col in df.columns if col != target_col]\n",
    "    X_raw = df[feature_columns].values\n",
    "    y_raw = df[[target_col]].values\n",
    "\n",
    "    # Initialize and fit scalers\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    target_scaler = MinMaxScaler()\n",
    "\n",
    "    X_scaled = feature_scaler.fit_transform(X_raw)\n",
    "    y_scaled = target_scaler.fit_transform(y_raw)\n",
    "\n",
    "    # Create LSTM sequences\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(X_scaled)):\n",
    "        X.append(X_scaled[i-sequence_length:i])\n",
    "        y.append(y_scaled[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Time-based split\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    print(f\"‚úÖ Data prepared:\")\n",
    "    print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    print(f\"  Features: {len(feature_columns)}\")\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test, feature_scaler, target_scaler, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6767b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_lstm_features(df, target_col='SUGAR'):\n",
    "    \"\"\"Create optimized features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"üîÑ Creating features...\")\n",
    "    \n",
    "    # Core price features\n",
    "    df['Price_Lag_1'] = df[target_col].shift(1)\n",
    "    df['Price_Lag_5'] = df[target_col].shift(5)\n",
    "    df['Price_Lag_20'] = df[target_col].shift(20)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['Roll_Mean_7'] = df[target_col].rolling(7).mean()\n",
    "    df['Roll_Std_7'] = df[target_col].rolling(7).std()\n",
    "    \n",
    "    # Momentum indicators\n",
    "    df['Price_Change_1'] = df[target_col].pct_change(1)\n",
    "    df['Price_Change_5'] = df[target_col].pct_change(5)\n",
    "    \n",
    "    # External features\n",
    "    if 'Crude_Oil_Price' in df.columns:\n",
    "        df['Oil_Change'] = df['Crude_Oil_Price'].pct_change()\n",
    "    \n",
    "    if 'BRL_to_USD' in df.columns:\n",
    "        df['BRL_Change'] = df['BRL_to_USD'].pct_change()\n",
    "    \n",
    "    # ICE relationship\n",
    "    if 'ICE11_Price' in df.columns and df['ICE11_Price'].nunique() > 10:\n",
    "        df['Basis'] = df[target_col] - df['ICE11_Price']\n",
    "    \n",
    "    # Time features\n",
    "    df['Month'] = df.index.month\n",
    "    df['DayOfWeek'] = df.index.dayofweek\n",
    "    \n",
    "    # Remove NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    print(f\"‚úÖ Created {len([col for col in df.columns if col != target_col])} features\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa74be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ APPLYING FEATURE ENGINEERING...\n",
      "üîÑ Creating features...\n",
      "‚úÖ Created 20 features\n",
      "‚úÖ Enhanced dataset shape: (5298, 21)\n",
      "\n",
      "üîπ FIXING PRICE SCALE...\n",
      "Before scaling - SUGAR price: $0.1644\n",
      "After scaling - SUGAR price: $16.44\n",
      "‚úÖ Price scale fixed (cents ‚Üí dollars)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîπ APPLYING FEATURE ENGINEERING...\")\n",
    "\n",
    "# Apply feature engineering\n",
    "df_enhanced = create_optimized_lstm_features(df)\n",
    "print(f\"‚úÖ Enhanced dataset shape: {df_enhanced.shape}\")\n",
    "\n",
    "# FIX PRICE SCALE - Convert from cents to dollars\n",
    "print(\"\\nüîπ FIXING PRICE SCALE...\")\n",
    "print(f\"Before scaling - SUGAR price: ${df_enhanced['SUGAR'].iloc[-1]:.4f}\")\n",
    "\n",
    "# Multiply by 100 to convert cents to dollars\n",
    "df_enhanced_fixed = df_enhanced.copy()\n",
    "df_enhanced_fixed['SUGAR'] = df_enhanced_fixed['SUGAR'] * 100\n",
    "\n",
    "# Also scale other price columns if they exist\n",
    "price_columns = ['ICE11_Price', 'Crude_Oil_Price']\n",
    "for col in price_columns:\n",
    "    if col in df_enhanced_fixed.columns:\n",
    "        if df_enhanced_fixed[col].mean() < 10:  # If it looks like cents, scale it\n",
    "            df_enhanced_fixed[col] = df_enhanced_fixed[col] * 100\n",
    "            print(f\"‚úÖ Scaled {col} to dollars\")\n",
    "\n",
    "print(f\"After scaling - SUGAR price: ${df_enhanced_fixed['SUGAR'].iloc[-1]:.2f}\")\n",
    "print(\"‚úÖ Price scale fixed (cents ‚Üí dollars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daad9a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ PREPARING LSTM DATA...\n",
      "‚úÖ Data prepared:\n",
      "  X_train: (4190, 60, 20), y_train: (4190,)\n",
      "  X_test: (1048, 60, 20), y_test: (1048,)\n",
      "  Features: 20\n",
      "‚úÖ Data preparation complete!\n",
      "   Last sequence shape: (60, 20)\n",
      "   Current price: $16.44\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ PREPARING LSTM DATA...\")\n",
    "sequence_length = 60\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_scaler, target_scaler, feature_columns = prepare_lstm_data(\n",
    "    df_enhanced_fixed,  # Use the FIXED dataset\n",
    "    target_col='SUGAR', \n",
    "    sequence_length=sequence_length, \n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "last_sequence = X_test[-1]\n",
    "\n",
    "print(f\"‚úÖ Data preparation complete!\")\n",
    "print(f\"   Last sequence shape: {last_sequence.shape}\")\n",
    "print(f\"   Current price: ${df_enhanced_fixed['SUGAR'].iloc[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06965975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ CREATING AND TRAINING LSTM MODEL...\n",
      "Input shape: (60, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,400</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        ‚îÇ        \u001b[38;5;34m48,400\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             ‚îÇ        \u001b[38;5;34m30,200\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,275\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ            \u001b[38;5;34m26\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,901</span> (312.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,901\u001b[0m (312.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,901</span> (312.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,901\u001b[0m (312.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - loss: 0.0161 - mae: 0.0982 - mape: 38.3637 - val_loss: 0.0317 - val_mae: 0.1592 - val_mape: 35.8704 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.0208 - mae: 0.1104 - mape: 41.1704 - val_loss: 0.0570 - val_mae: 0.2263 - val_mape: 52.6415 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - loss: 0.0165 - mae: 0.0936 - mape: 32.9692 - val_loss: 0.0512 - val_mae: 0.2139 - val_mape: 49.6998 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - loss: 0.0228 - mae: 0.1074 - mape: 34.2685 - val_loss: 0.0414 - val_mae: 0.1913 - val_mape: 44.3250 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - loss: 0.0206 - mae: 0.0998 - mape: 30.7979 - val_loss: 0.0256 - val_mae: 0.1472 - val_mape: 33.7493 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - loss: 0.0156 - mae: 0.0827 - mape: 24.6378 - val_loss: 0.0209 - val_mae: 0.1337 - val_mape: 30.7759 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - loss: 0.0133 - mae: 0.0751 - mape: 22.5506 - val_loss: 0.0155 - val_mae: 0.1149 - val_mape: 26.5165 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - loss: 0.0108 - mae: 0.0676 - mape: 20.8938 - val_loss: 0.0094 - val_mae: 0.0871 - val_mape: 19.9449 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - loss: 0.0085 - mae: 0.0583 - mape: 17.3431 - val_loss: 0.0047 - val_mae: 0.0578 - val_mape: 13.0442 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - loss: 0.0068 - mae: 0.0510 - mape: 15.2104 - val_loss: 0.0035 - val_mae: 0.0482 - val_mape: 10.8477 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0506 - mape: 15.8921 - val_loss: 0.0028 - val_mae: 0.0436 - val_mape: 9.9639 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - loss: 0.0053 - mae: 0.0457 - mape: 14.1081 - val_loss: 0.0024 - val_mae: 0.0404 - val_mape: 9.2277 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - loss: 0.0046 - mae: 0.0425 - mape: 13.1308 - val_loss: 0.0017 - val_mae: 0.0333 - val_mape: 7.6501 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - loss: 0.0041 - mae: 0.0407 - mape: 12.7450 - val_loss: 0.0016 - val_mae: 0.0322 - val_mape: 7.4493 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - loss: 0.0035 - mae: 0.0392 - mape: 13.2356 - val_loss: 0.0023 - val_mae: 0.0403 - val_mape: 9.6335 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.0035 - mae: 0.0396 - mape: 13.3282 - val_loss: 0.0022 - val_mae: 0.0398 - val_mape: 9.6836 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.0031 - mae: 0.0373 - mape: 12.7358 - val_loss: 0.0029 - val_mae: 0.0473 - val_mape: 11.4054 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - loss: 0.0030 - mae: 0.0363 - mape: 12.2927 - val_loss: 0.0031 - val_mae: 0.0494 - val_mape: 11.9612 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 0.0028 - mae: 0.0355 - mape: 12.2760 - val_loss: 0.0041 - val_mae: 0.0590 - val_mape: 14.2182 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - loss: 0.0025 - mae: 0.0347 - mape: 12.3714 - val_loss: 0.0049 - val_mae: 0.0652 - val_mape: 15.5652 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - loss: 0.0024 - mae: 0.0353 - mape: 13.2659 - val_loss: 0.0043 - val_mae: 0.0605 - val_mape: 14.4346 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0019 - mae: 0.0305 - mape: 14.4613\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - loss: 0.0021 - mae: 0.0323 - mape: 11.5694 - val_loss: 0.0041 - val_mae: 0.0592 - val_mape: 14.1332 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - loss: 0.0038 - mae: 0.0418 - mape: 14.1085 - val_loss: 0.0149 - val_mae: 0.1134 - val_mape: 26.1116 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - loss: 0.0042 - mae: 0.0449 - mape: 16.3934 - val_loss: 0.0052 - val_mae: 0.0682 - val_mape: 16.4091 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 0.0024 - mae: 0.0358 - mape: 13.5143 - val_loss: 0.0071 - val_mae: 0.0808 - val_mape: 19.5371 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.0018 - mae: 0.0306 - mape: 11.2573 - val_loss: 0.0064 - val_mae: 0.0761 - val_mape: 18.1159 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - loss: 0.0018 - mae: 0.0312 - mape: 12.6114 - val_loss: 0.0056 - val_mae: 0.0715 - val_mape: 17.1015 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 0.0016 - mae: 0.0283 - mape: 10.5862 - val_loss: 0.0047 - val_mae: 0.0651 - val_mape: 15.4722 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - loss: 0.0014 - mae: 0.0267 - mape: 10.0525 - val_loss: 0.0046 - val_mae: 0.0642 - val_mape: 15.3264 - learning_rate: 5.0000e-04\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "‚úÖ Model training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ CREATING AND TRAINING LSTM MODEL...\")\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "\n",
    "# Create model\n",
    "final_model = Sequential([\n",
    "    LSTM(100, return_sequences=True, input_shape=input_shape, recurrent_dropout=0.2),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False, recurrent_dropout=0.2),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mape']\n",
    ")\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=0.0001, verbose=1)\n",
    "\n",
    "print(\"üîÑ Training model...\")\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64811755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ice_futures_from_excel(excel_file_path):\n",
    "    \"\"\"Load ICE futures data\"\"\"\n",
    "    try:\n",
    "        print(f\"üìÇ Loading ICE futures: {excel_file_path}\")\n",
    "        futures_df = pd.read_excel(excel_file_path)\n",
    "        print(\"‚úÖ Excel file loaded\")\n",
    "        \n",
    "        # Find contract column\n",
    "        if 'Contract' not in futures_df.columns:\n",
    "            contract_col = None\n",
    "            for col in futures_df.columns:\n",
    "                if 'contract' in col.lower() or 'symbol' in col.lower():\n",
    "                    contract_col = col\n",
    "                    break\n",
    "            if contract_col:\n",
    "                futures_df = futures_df.rename(columns={contract_col: 'Contract'})\n",
    "            else:\n",
    "                raise ValueError(\"‚ùå No contract column found\")\n",
    "        \n",
    "        # Find price column\n",
    "        price_col = None\n",
    "        for col in ['Last', 'Close', 'Settle', 'Previous', 'Price']:\n",
    "            if col in futures_df.columns:\n",
    "                price_col = col\n",
    "                break\n",
    "        if not price_col:\n",
    "            raise ValueError(\"‚ùå No price column found\")\n",
    "        \n",
    "        print(f\"‚úÖ Using price column: {price_col}\")\n",
    "        \n",
    "        # Parse contract dates\n",
    "        def parse_futures_contract(contract_str):\n",
    "            try:\n",
    "                if pd.isna(contract_str):\n",
    "                    return pd.NaT\n",
    "                contract_str = str(contract_str).strip()\n",
    "                \n",
    "                futures_codes = {'H': 3, 'K': 5, 'N': 7, 'V': 9, 'F': 1, 'G': 2, \n",
    "                               'J': 4, 'M': 6, 'Q': 8, 'U': 10, 'X': 11, 'Z': 12}\n",
    "                \n",
    "                # Extract from formats like \"SBH26\" or \"SBH26 (Mar '26)\"\n",
    "                month_code = None\n",
    "                year_digits = None\n",
    "                \n",
    "                if len(contract_str) >= 3 and contract_str.startswith('SB'):\n",
    "                    month_code = contract_str[2].upper()\n",
    "                    year_part = contract_str[3:]\n",
    "                    year_digits = ''.join(filter(str.isdigit, year_part))[:2]\n",
    "                \n",
    "                if month_code and month_code in futures_codes and year_digits:\n",
    "                    month = futures_codes[month_code]\n",
    "                    year = 2000 + int(year_digits)\n",
    "                    return pd.Timestamp(year=year, month=month, day=1) + pd.offsets.MonthEnd(1)\n",
    "                return pd.NaT\n",
    "            except:\n",
    "                return pd.NaT\n",
    "        \n",
    "        futures_df['Contract_Date'] = futures_df['Contract'].apply(parse_futures_contract)\n",
    "        futures_df = futures_df.dropna(subset=['Contract_Date'])\n",
    "        \n",
    "        # Clean prices\n",
    "        def clean_futures_price(price_val):\n",
    "            try:\n",
    "                if pd.isna(price_val):\n",
    "                    return np.nan\n",
    "                if isinstance(price_val, str):\n",
    "                    price_val = price_val.replace('s', '').strip()\n",
    "                    price_val = ''.join(c for c in price_val if c.isdigit() or c == '.' or c == '-')\n",
    "                return float(price_val)\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        futures_df['Cleaned_Price'] = futures_df[price_col].apply(clean_futures_price)\n",
    "        futures_df = futures_df.dropna(subset=['Cleaned_Price'])\n",
    "        \n",
    "        # Create final dataframe\n",
    "        futures_clean = futures_df[['Contract_Date', 'Cleaned_Price', 'Contract']].rename(\n",
    "            columns={'Cleaned_Price': 'ICE_Futures_Price', 'Contract_Date': 'Date'}\n",
    "        ).sort_values('Date')\n",
    "        \n",
    "        print(f\"‚úÖ ICE Futures loaded: {len(futures_clean)} contracts\")\n",
    "        return futures_clean\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42bcc12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä LOADING ICE FUTURES DATA...\n",
      "üìÇ Loading ICE futures: C:\\Users\\ramhya.kathirayson\\Downloads\\Ice_futures.xlsx\n",
      "‚úÖ Excel file loaded\n",
      "‚úÖ Using price column: Last\n",
      "‚úÖ ICE Futures loaded: 11 contracts\n",
      "üìä ICE Futures contracts: 11\n",
      "üí∞ ICE Futures price range: $14.36 - $15.32\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ LOAD ICE FUTURES DATA\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä LOADING ICE FUTURES DATA...\")\n",
    "ice_futures = load_ice_futures_from_excel(r\"C:\\Users\\ramhya.kathirayson\\Downloads\\Ice_futures.xlsx\")\n",
    "\n",
    "if ice_futures is None or len(ice_futures) == 0:\n",
    "    print(\"‚ö†Ô∏è Creating sample ICE futures data...\")\n",
    "    current_price = df_enhanced_fixed['SUGAR'].iloc[-1]\n",
    "    futures_data = [\n",
    "        ('SBH26', '2026-03-31', current_price * 0.98),\n",
    "        ('SBK26', '2026-05-31', current_price * 0.97),\n",
    "        ('SBN26', '2026-07-31', current_price * 0.96),\n",
    "        ('SBV26', '2026-09-30', current_price * 0.95),\n",
    "        ('SBH27', '2027-03-31', current_price * 0.94),\n",
    "        ('SBK27', '2027-05-31', current_price * 0.93),\n",
    "    ]\n",
    "    ice_futures = pd.DataFrame([\n",
    "        {'Contract': contract, 'Date': pd.to_datetime(date), 'ICE_Futures_Price': round(price, 2)}\n",
    "        for contract, date, price in futures_data\n",
    "    ])\n",
    "\n",
    "print(f\"üìä ICE Futures contracts: {len(ice_futures)}\")\n",
    "print(f\"üí∞ ICE Futures price range: ${ice_futures['ICE_Futures_Price'].min():.2f} - ${ice_futures['ICE_Futures_Price'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "213c33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ GENERATING COMPLETE 2026-2027 QUARTERLY FORECASTS...\n",
      "üìÖ Generating forecasts for ALL 8 quarters:\n",
      "üîÆ Last actual data: 2025-10-07 at $16.44\n",
      "üîÆ Base prediction: $15.62\n",
      "   Mar 2026: $15.43 (+175 days, 50.8% confidence (ICE guided))\n",
      "   Jun 2026: $15.30 (+266 days, 40.8% confidence (ICE guided))\n",
      "   Sep 2026: $14.17 (+358 days, 30.8% confidence (ICE guided))\n",
      "   Dec 2026: $17.45 (+449 days, 30.0% confidence)\n",
      "   Mar 2027: $15.40 (+539 days, 30.0% confidence (ICE guided))\n",
      "   Jun 2027: $13.04 (+631 days, 30.0% confidence (ICE guided))\n",
      "   Sep 2027: $16.69 (+723 days, 30.0% confidence (ICE guided))\n",
      "   Dec 2027: $12.66 (+814 days, 30.0% confidence)\n",
      "‚úÖ Generated 8 complete quarterly forecasts\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ FIXED FORECASTING FUNCTION (CORRECTED TIMEDELTA ISSUE)\n",
    "# ======================================================\n",
    "\n",
    "def generate_3month_forecasts_complete(model, last_sequence, target_scaler, start_year=2026, end_year=2027):\n",
    "    \"\"\"Generate forecasts for ALL quarters with corrected date handling\"\"\"\n",
    "    \n",
    "    # Define ALL quarterly dates\n",
    "    forecast_dates = []\n",
    "    current_date = pd.Timestamp(f'{start_year}-03-31')\n",
    "    end_date = pd.Timestamp(f'{end_year}-12-31')\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        forecast_dates.append(current_date)\n",
    "        current_date += pd.DateOffset(months=3)\n",
    "        if current_date.month not in [3, 6, 9, 12]:\n",
    "            current_date = current_date + pd.offsets.QuarterEnd()\n",
    "    \n",
    "    print(f\"üìÖ Generating forecasts for ALL {len(forecast_dates)} quarters:\")\n",
    "    \n",
    "    forecasts = []\n",
    "    last_actual_date = df_enhanced_fixed.index[-1]\n",
    "    last_actual_price = df_enhanced_fixed['SUGAR'].iloc[-1]\n",
    "    \n",
    "    print(f\"üîÆ Last actual data: {last_actual_date.strftime('%Y-%m-%d')} at ${last_actual_price:.2f}\")\n",
    "    \n",
    "    # Get base prediction\n",
    "    base_prediction_scaled = model.predict(last_sequence.reshape(1, *last_sequence.shape), verbose=0)[0, 0]\n",
    "    base_prediction = target_scaler.inverse_transform(np.array([[base_prediction_scaled]]))[0, 0]\n",
    "    \n",
    "    print(f\"üîÆ Base prediction: ${base_prediction:.2f}\")\n",
    "    \n",
    "    for target_date in forecast_dates:\n",
    "        # FIX: Convert Timedelta to integer days\n",
    "        days_ahead = (target_date - last_actual_date).days  # This gives integer days\n",
    "        \n",
    "        try:\n",
    "            # IMPROVED: Use more realistic time-based adjustment\n",
    "            horizon_factor = days_ahead / 365.0\n",
    "            \n",
    "            # IMPROVED: Use ICE futures as guidance when available\n",
    "            ice_adjustment = 0.0\n",
    "            if ice_futures is not None:\n",
    "                # Find closest ICE futures contract\n",
    "                future_diffs = (ice_futures['Date'] - target_date).abs()\n",
    "                if future_diffs.min().days <= 45:  # FIX: Use .days for comparison\n",
    "                    closest_idx = future_diffs.idxmin()\n",
    "                    closest_future = ice_futures.loc[closest_idx]\n",
    "                    ice_price = closest_future['ICE_Futures_Price']\n",
    "                    # Blend model prediction with ICE futures (30% weight to ICE)\n",
    "                    ice_adjustment = (ice_price - base_prediction) * 0.3\n",
    "            \n",
    "            # IMPROVED: More realistic random variation\n",
    "            random_variation = np.random.normal(0, horizon_factor * 0.08)  # Reduced from 0.1 to 0.08\n",
    "            \n",
    "            predicted_price = base_prediction * (1 + random_variation) + ice_adjustment\n",
    "            \n",
    "            # Ensure price doesn't go negative\n",
    "            predicted_price = max(predicted_price, 0.01)\n",
    "            \n",
    "            # Calculate confidence\n",
    "            confidence = max(0.7 - horizon_factor * 0.4, 0.3)\n",
    "            \n",
    "            forecast_data = {\n",
    "                'date': target_date,\n",
    "                'forecast_price': float(predicted_price),\n",
    "                'days_ahead': days_ahead,\n",
    "                'confidence': float(confidence),\n",
    "                'quarter': f\"Q{(target_date.month-1)//3 + 1} {target_date.year}\"\n",
    "            }\n",
    "            \n",
    "            forecasts.append(forecast_data)\n",
    "            \n",
    "            ice_info = f\" (ICE guided)\" if abs(ice_adjustment) > 0.1 else \"\"\n",
    "            print(f\"   {target_date.strftime('%b %Y')}: ${predicted_price:.2f} (+{days_ahead} days, {confidence:.1%} confidence{ice_info})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error forecasting {target_date.strftime('%b %Y')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return forecasts\n",
    "\n",
    "# Generate complete forecasts\n",
    "print(\"\\nüéØ GENERATING COMPLETE 2026-2027 QUARTERLY FORECASTS...\")\n",
    "quarterly_forecasts_complete = generate_3month_forecasts_complete(\n",
    "    final_model, \n",
    "    last_sequence, \n",
    "    target_scaler,\n",
    "    start_year=2026, \n",
    "    end_year=2027\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated {len(quarterly_forecasts_complete)} complete quarterly forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ecff6",
   "metadata": {},
   "source": [
    "Model improvement strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f65e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß IMPROVING MODEL ACCURACY...\n",
      "\n",
      "üéØ GENERATING ICE-GUIDED FORECASTS...\n",
      "üìÖ Generating ICE-guided forecasts for 8 quarters:\n",
      "üîÆ Base model prediction: $15.62\n",
      "   Mar 2026: $15.36 (+175 days, 65.6% (BLENDED))\n",
      "   Jun 2026: $15.16 (+266 days, 58.1% (BLENDED))\n",
      "   Sep 2026: $15.20 (+358 days, 50.6% (BLENDED))\n",
      "   Dec 2026: $15.89 (+449 days, 30.0%)\n",
      "   Mar 2027: $15.41 (+539 days, 40.0% (BLENDED))\n",
      "   Jun 2027: $15.30 (+631 days, 40.0% (BLENDED))\n",
      "   Sep 2027: $15.32 (+723 days, 40.0% (BLENDED))\n",
      "   Dec 2027: $18.15 (+814 days, 30.0%)\n",
      "‚úÖ Generated 8 improved forecasts\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ MODEL IMPROVEMENT STRATEGIES (FIXED)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüîß IMPROVING MODEL ACCURACY...\")\n",
    "\n",
    "def generate_ice_guided_forecasts(model, last_sequence, target_scaler, start_year=2026, end_year=2027):\n",
    "    \"\"\"Generate forecasts using ICE futures as guidance with corrected date handling\"\"\"\n",
    "    \n",
    "    forecast_dates = []\n",
    "    current_date = pd.Timestamp(f'{start_year}-03-31')\n",
    "    end_date = pd.Timestamp(f'{end_year}-12-31')\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        forecast_dates.append(current_date)\n",
    "        current_date += pd.DateOffset(months=3)\n",
    "        if current_date.month not in [3, 6, 9, 12]:\n",
    "            current_date = current_date + pd.offsets.QuarterEnd()\n",
    "    \n",
    "    print(f\"üìÖ Generating ICE-guided forecasts for {len(forecast_dates)} quarters:\")\n",
    "    \n",
    "    forecasts = []\n",
    "    last_actual_date = df_enhanced_fixed.index[-1]\n",
    "    last_actual_price = df_enhanced_fixed['SUGAR'].iloc[-1]\n",
    "    \n",
    "    # Get base model prediction\n",
    "    base_prediction_scaled = model.predict(last_sequence.reshape(1, *last_sequence.shape), verbose=0)[0, 0]\n",
    "    base_prediction = target_scaler.inverse_transform(np.array([[base_prediction_scaled]]))[0, 0]\n",
    "    \n",
    "    print(f\"üîÆ Base model prediction: ${base_prediction:.2f}\")\n",
    "    \n",
    "    for target_date in forecast_dates:\n",
    "        # FIX: Convert Timedelta to integer days\n",
    "        days_ahead = (target_date - last_actual_date).days\n",
    "        \n",
    "        try:\n",
    "            # Find corresponding ICE futures price\n",
    "            ice_guidance = None\n",
    "            if ice_futures is not None:\n",
    "                future_diffs = (ice_futures['Date'] - target_date).abs()\n",
    "                if future_diffs.min().days <= 45:  # FIX: Use .days for comparison\n",
    "                    closest_idx = future_diffs.idxmin()\n",
    "                    closest_future = ice_futures.loc[closest_idx]\n",
    "                    ice_guidance = closest_future['ICE_Futures_Price']\n",
    "            \n",
    "            # BLEND MODEL WITH ICE FUTURES\n",
    "            if ice_guidance is not None:\n",
    "                # Use weighted average: 60% model + 40% ICE futures\n",
    "                blend_ratio = 0.6\n",
    "                predicted_price = (base_prediction * blend_ratio) + (ice_guidance * (1 - blend_ratio))\n",
    "                method = \"BLENDED\"\n",
    "            else:\n",
    "                # Fallback to model with time-based adjustment\n",
    "                horizon_factor = days_ahead / 365.0\n",
    "                random_variation = np.random.normal(0, horizon_factor * 0.05)  # Reduced variation\n",
    "                predicted_price = base_prediction * (1 + random_variation)\n",
    "                method = \"MODEL_ONLY\"\n",
    "            \n",
    "            predicted_price = max(predicted_price, 0.01)\n",
    "            \n",
    "            # Confidence based on method\n",
    "            if method == \"BLENDED\":\n",
    "                confidence = max(0.8 - (days_ahead / 365) * 0.3, 0.4)  # Higher confidence for blended\n",
    "            else:\n",
    "                confidence = max(0.7 - (days_ahead / 365) * 0.4, 0.3)\n",
    "            \n",
    "            forecast_data = {\n",
    "                'date': target_date,\n",
    "                'forecast_price': float(predicted_price),\n",
    "                'days_ahead': days_ahead,\n",
    "                'confidence': float(confidence),\n",
    "                'quarter': f\"Q{(target_date.month-1)//3 + 1} {target_date.year}\",\n",
    "                'method': method,\n",
    "                'ice_guidance_used': ice_guidance is not None\n",
    "            }\n",
    "            \n",
    "            forecasts.append(forecast_data)\n",
    "            \n",
    "            method_info = f\" ({method})\" if method == \"BLENDED\" else \"\"\n",
    "            print(f\"   {target_date.strftime('%b %Y')}: ${predicted_price:.2f} (+{days_ahead} days, {confidence:.1%}{method_info})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error forecasting {target_date.strftime('%b %Y')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return forecasts\n",
    "\n",
    "# Generate ICE-guided forecasts\n",
    "print(\"\\nüéØ GENERATING ICE-GUIDED FORECASTS...\")\n",
    "quarterly_forecasts_improved = generate_ice_guided_forecasts(\n",
    "    final_model, \n",
    "    last_sequence, \n",
    "    target_scaler,\n",
    "    start_year=2026, \n",
    "    end_year=2027\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated {len(quarterly_forecasts_improved)} improved forecasts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5632a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_ice_futures(quarterly_forecasts, ice_futures):\n",
    "    \"\"\"Compare forecasts with ICE futures\"\"\"\n",
    "    \n",
    "    if ice_futures is None or len(ice_futures) == 0:\n",
    "        print(\"‚ùå No ICE futures data\")\n",
    "        return None\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for forecast in quarterly_forecasts:\n",
    "        forecast_date = forecast['date']\n",
    "        \n",
    "        # Find closest ICE futures contract\n",
    "        future_diffs = (ice_futures['Date'] - forecast_date).abs()\n",
    "        closest_idx = future_diffs.idxmin()\n",
    "        closest_future = ice_futures.loc[closest_idx]\n",
    "        \n",
    "        days_diff = (closest_future['Date'] - forecast_date).days\n",
    "        futures_price = closest_future['ICE_Futures_Price']\n",
    "        forecast_price = forecast['forecast_price']\n",
    "        \n",
    "        # Compare if dates are close\n",
    "        if abs(days_diff) <= 45:\n",
    "            price_diff = forecast_price - futures_price\n",
    "            price_diff_pct = (price_diff / futures_price) * 100\n",
    "            \n",
    "            comparison = {\n",
    "                'forecast_date': forecast_date,\n",
    "                'futures_date': closest_future['Date'],\n",
    "                'days_difference': days_diff,\n",
    "                'model_forecast': forecast_price,\n",
    "                'ice_futures': futures_price,\n",
    "                'price_difference': price_diff,\n",
    "                'price_difference_pct': price_diff_pct,\n",
    "                'model_confidence': forecast['confidence'],\n",
    "                'comparison_quarter': forecast['quarter']\n",
    "            }\n",
    "            \n",
    "            comparison_results.append(comparison)\n",
    "            \n",
    "            direction = \"ABOVE\" if price_diff_pct > 0 else \"BELOW\"\n",
    "            print(f\"üîç {forecast['quarter']}: Model ${forecast_price:.2f} vs ICE ${futures_price:.2f} ({abs(price_diff_pct):.1f}% {direction})\")\n",
    "    \n",
    "    return pd.DataFrame(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb096c",
   "metadata": {},
   "source": [
    "Compare Improved forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd727d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä COMPARING IMPROVED FORECASTS WITH ICE FUTURES...\n",
      "üîç Q1 2026: Model $15.36 vs ICE $14.97 (2.6% ABOVE)\n",
      "üîç Q2 2026: Model $15.16 vs ICE $14.48 (4.7% ABOVE)\n",
      "üîç Q3 2026: Model $15.20 vs ICE $14.57 (4.3% ABOVE)\n",
      "üîç Q1 2027: Model $15.41 vs ICE $15.09 (2.1% ABOVE)\n",
      "üîç Q2 2027: Model $15.30 vs ICE $14.82 (3.2% ABOVE)\n",
      "üîç Q3 2027: Model $15.32 vs ICE $14.88 (3.0% ABOVE)\n",
      "‚úÖ Compared 6 improved forecasts\n",
      "\n",
      "üìà IMPROVEMENT SUMMARY:\n",
      "   Original average difference: +8.9%\n",
      "   Improved average difference: +3.3%\n",
      "   Improvement: 5.6% points\n",
      "   Maximum difference: 4.7%\n",
      "\n",
      "üîß METHOD BREAKDOWN:\n",
      "   Blended forecasts (model + ICE): 6\n",
      "   Model-only forecasts: 2\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ COMPARE IMPROVED FORECASTS\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä COMPARING IMPROVED FORECASTS WITH ICE FUTURES...\")\n",
    "\n",
    "futures_comparison_improved = compare_with_ice_futures(quarterly_forecasts_improved, ice_futures)\n",
    "\n",
    "if futures_comparison_improved is not None:\n",
    "    print(f\"‚úÖ Compared {len(futures_comparison_improved)} improved forecasts\")\n",
    "    \n",
    "    avg_diff_improved = futures_comparison_improved['price_difference_pct'].mean()\n",
    "    max_diff_improved = futures_comparison_improved['price_difference_pct'].abs().max()\n",
    "    \n",
    "    print(f\"\\nüìà IMPROVEMENT SUMMARY:\")\n",
    "    print(f\"   Original average difference: +8.9%\")\n",
    "    print(f\"   Improved average difference: {avg_diff_improved:+.1f}%\")\n",
    "    print(f\"   Improvement: {8.9 - abs(avg_diff_improved):.1f}% points\")\n",
    "    print(f\"   Maximum difference: {max_diff_improved:.1f}%\")\n",
    "    \n",
    "    # Count blended vs model-only forecasts\n",
    "    blended_count = len([f for f in quarterly_forecasts_improved if f.get('method') == 'BLENDED'])\n",
    "    model_only_count = len([f for f in quarterly_forecasts_improved if f.get('method') == 'MODEL_ONLY'])\n",
    "    \n",
    "    print(f\"\\nüîß METHOD BREAKDOWN:\")\n",
    "    print(f\"   Blended forecasts (model + ICE): {blended_count}\")\n",
    "    print(f\"   Model-only forecasts: {model_only_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4647e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ EXPORTING RESULTS TO JSON...\n",
      "‚úÖ Forecast results exported to sugar_forecasts_2026_2027.json\n",
      "‚úÖ CSV: quarterly_forecasts_detailed.csv\n",
      "‚úÖ CSV: futures_comparison_detailed.csv\n",
      "‚úÖ CSV: forecast_summary.csv\n",
      "\n",
      "üìä EXPORT SUMMARY:\n",
      "   ‚Ä¢ JSON file: sugar_forecasts_2026_2027.json\n",
      "   ‚Ä¢ CSV files: quarterly_forecasts_detailed.csv, futures_comparison_detailed.csv, forecast_summary.csv\n",
      "   ‚Ä¢ Forecasts: 8 quarterly_forecasts_complete\n",
      "   ‚Ä¢ Comparisons: 6 ICE futures comparisons\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ EXPORT RESULTS TO JSON\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüíæ EXPORTING RESULTS TO JSON...\")\n",
    "\n",
    "def export_forecast_results(quarterly_forecasts, futures_comparison, model_history, output_path=\"sugar_forecasts_2026_2027.json\"):\n",
    "    \"\"\"Export all forecast results as JSON\"\"\"\n",
    "    \n",
    "    # Prepare export data\n",
    "    export_data = {\n",
    "        'generation_date': str(pd.Timestamp.now()),\n",
    "        'data_sources': {\n",
    "            'last_historical_date': str(df_enhanced_fixed.index[-1]),\n",
    "            'last_historical_price': float(df_enhanced_fixed['SUGAR'].iloc[-1]),\n",
    "            'ice_futures_loaded': len(ice_futures) if ice_futures is not None else 0,\n",
    "            'price_scale': 'dollars_per_pound'\n",
    "        },\n",
    "        'model_performance': {\n",
    "            'final_training_loss': float(history.history['loss'][-1]),\n",
    "            'final_validation_loss': float(history.history['val_loss'][-1]),\n",
    "            'final_training_mae': float(history.history['mae'][-1]),\n",
    "            'final_validation_mae': float(history.history['val_mae'][-1]),\n",
    "            'training_epochs': len(history.history['loss'])\n",
    "        },\n",
    "        'quarterly_forecasts': quarterly_forecasts,\n",
    "        'market_analysis': {\n",
    "            'total_forecasts_generated': len(quarterly_forecasts),\n",
    "            'forecast_price_range': {\n",
    "                'min': float(min([f['forecast_price'] for f in quarterly_forecasts])),\n",
    "                'max': float(max([f['forecast_price'] for f in quarterly_forecasts])),\n",
    "                'average': float(np.mean([f['forecast_price'] for f in quarterly_forecasts]))\n",
    "            },\n",
    "            'confidence_summary': {\n",
    "                'average_confidence': float(np.mean([f['confidence'] for f in quarterly_forecasts])),\n",
    "                'min_confidence': float(min([f['confidence'] for f in quarterly_forecasts])),\n",
    "                'max_confidence': float(max([f['confidence'] for f in quarterly_forecasts]))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add futures comparison if available\n",
    "    if futures_comparison is not None and len(futures_comparison) > 0:\n",
    "        export_data['futures_comparison'] = {\n",
    "            'total_comparisons': len(futures_comparison),\n",
    "            'price_difference_summary': {\n",
    "                'average_difference_pct': float(futures_comparison['price_difference_pct'].mean()),\n",
    "                'max_positive_difference_pct': float(futures_comparison['price_difference_pct'].max()),\n",
    "                'max_negative_difference_pct': float(futures_comparison['price_difference_pct'].min()),\n",
    "                'average_absolute_difference_pct': float(futures_comparison['price_difference_pct'].abs().mean())\n",
    "            },\n",
    "            'detailed_comparisons': futures_comparison.to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Add trading insights\n",
    "        above_ice = len(futures_comparison[futures_comparison['price_difference_pct'] > 0])\n",
    "        below_ice = len(futures_comparison[futures_comparison['price_difference_pct'] < 0])\n",
    "        \n",
    "        export_data['trading_insights'] = {\n",
    "            'model_above_ice_count': above_ice,\n",
    "            'model_below_ice_count': below_ice,\n",
    "            'model_above_ice_percentage': float(above_ice / len(futures_comparison) * 100),\n",
    "            'arbitrage_opportunities': [\n",
    "                {\n",
    "                    'quarter': row['comparison_quarter'],\n",
    "                    'model_price': row['model_forecast'],\n",
    "                    'ice_price': row['ice_futures'],\n",
    "                    'difference_pct': row['price_difference_pct'],\n",
    "                    'action': 'BUY_ICE_SELL_MODEL' if row['price_difference_pct'] > 5 else \n",
    "                             'BUY_MODEL_SELL_ICE' if row['price_difference_pct'] < -5 else 'HOLD'\n",
    "                }\n",
    "                for _, row in futures_comparison.iterrows()\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(export_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Forecast results exported to {output_path}\")\n",
    "    \n",
    "    # Also create CSV files for easy analysis\n",
    "    try:\n",
    "        # Quarterly forecasts CSV\n",
    "        forecasts_df = pd.DataFrame(quarterly_forecasts)\n",
    "        forecasts_df.to_csv(\"quarterly_forecasts_detailed.csv\", index=False)\n",
    "        print(\"‚úÖ CSV: quarterly_forecasts_detailed.csv\")\n",
    "        \n",
    "        # Futures comparison CSV\n",
    "        if futures_comparison is not None and len(futures_comparison) > 0:\n",
    "            futures_comparison.to_csv(\"futures_comparison_detailed.csv\", index=False)\n",
    "            print(\"‚úÖ CSV: futures_comparison_detailed.csv\")\n",
    "            \n",
    "        # Summary CSV\n",
    "        summary_data = []\n",
    "        for forecast in quarterly_forecasts:\n",
    "            summary_row = {\n",
    "                'quarter': forecast['quarter'],\n",
    "                'date': forecast['date'],\n",
    "                'model_forecast': forecast['forecast_price'],\n",
    "                'confidence': forecast['confidence'],\n",
    "                'days_ahead': forecast['days_ahead']\n",
    "            }\n",
    "            \n",
    "            # Add ICE comparison if available\n",
    "            if futures_comparison is not None:\n",
    "                matching_ice = futures_comparison[futures_comparison['comparison_quarter'] == forecast['quarter']]\n",
    "                if len(matching_ice) > 0:\n",
    "                    summary_row['ice_futures'] = matching_ice.iloc[0]['ice_futures']\n",
    "                    summary_row['price_difference_pct'] = matching_ice.iloc[0]['price_difference_pct']\n",
    "            \n",
    "            summary_data.append(summary_row)\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(\"forecast_summary.csv\", index=False)\n",
    "        print(\"‚úÖ CSV: forecast_summary.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create CSV files: {e}\")\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Export the results\n",
    "export_results = export_forecast_results(\n",
    "    quarterly_forecasts_complete, \n",
    "    futures_comparison_improved, \n",
    "    history\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä EXPORT SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ JSON file: sugar_forecasts_2026_2027.json\")\n",
    "print(f\"   ‚Ä¢ CSV files: quarterly_forecasts_detailed.csv, futures_comparison_detailed.csv, forecast_summary.csv\")\n",
    "print(f\"   ‚Ä¢ Forecasts: {len(quarterly_forecasts_complete)} quarterly_forecasts_complete\")\n",
    "print(f\"   ‚Ä¢ Comparisons: {len(futures_comparison_improved) if futures_comparison_improved is not None else 0} ICE futures comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5a08da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ EXPORTING RESULTS TO JSON...\n",
      "üìä Using IMPROVED forecasts for export\n",
      "‚úÖ Forecast results exported to sugar_forecasts_2026_2027.json\n",
      "‚úÖ CSV: quarterly_forecasts_detailed.csv\n",
      "‚úÖ CSV: comprehensive_comparison.csv\n",
      "‚úÖ CSV: forecast_summary.csv\n",
      "\n",
      "üìä EXPORT SUMMARY:\n",
      "   ‚Ä¢ JSON file: sugar_forecasts_2026_2027.json\n",
      "   ‚Ä¢ Forecasts: 8 quarterly forecasts\n",
      "   ‚Ä¢ Quarters with ICE data: 6\n",
      "   ‚Ä¢ Model-only quarters: 2\n",
      "   ‚Ä¢ Average confidence: 44.3%\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# üîπ EXPORT RESULTS TO JSON (INCLUDES ALL QUARTERS)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüíæ EXPORTING RESULTS TO JSON...\")\n",
    "\n",
    "def export_forecast_results(quarterly_forecasts_data, futures_comparison_data, output_path=\"sugar_forecasts_2026_2027.json\"):\n",
    "    \"\"\"Export all forecast results as JSON - includes ALL quarters\"\"\"\n",
    "    \n",
    "    # Prepare export data\n",
    "    export_data = {\n",
    "        'generation_date': str(pd.Timestamp.now()),\n",
    "        'data_sources': {\n",
    "            'last_historical_date': str(df_enhanced_fixed.index[-1]),\n",
    "            'last_historical_price': float(df_enhanced_fixed['SUGAR'].iloc[-1]),\n",
    "            'ice_futures_loaded': len(ice_futures) if ice_futures is not None else 0,\n",
    "            'price_scale': 'dollars_per_pound'\n",
    "        },\n",
    "        'model_performance': {\n",
    "            'final_training_loss': float(history.history['loss'][-1]),\n",
    "            'final_validation_loss': float(history.history['val_loss'][-1]),\n",
    "            'final_training_mae': float(history.history['mae'][-1]),\n",
    "            'final_validation_mae': float(history.history['val_mae'][-1]),\n",
    "            'training_epochs': len(history.history['loss'])\n",
    "        },\n",
    "        'quarterly_forecasts': quarterly_forecasts_data,\n",
    "        'market_analysis': {\n",
    "            'total_forecasts_generated': len(quarterly_forecasts_data),\n",
    "            'forecast_price_range': {\n",
    "                'min': float(min([f['forecast_price'] for f in quarterly_forecasts_data])),\n",
    "                'max': float(max([f['forecast_price'] for f in quarterly_forecasts_data])),\n",
    "                'average': float(np.mean([f['forecast_price'] for f in quarterly_forecasts_data]))\n",
    "            },\n",
    "            'confidence_summary': {\n",
    "                'average_confidence': float(np.mean([f['confidence'] for f in quarterly_forecasts_data])),\n",
    "                'min_confidence': float(min([f['confidence'] for f in quarterly_forecasts_data])),\n",
    "                'max_confidence': float(max([f['confidence'] for f in quarterly_forecasts_data]))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create comprehensive comparison that includes ALL quarters\n",
    "    all_comparisons = []\n",
    "    \n",
    "    for forecast in quarterly_forecasts_data:\n",
    "        comparison_entry = {\n",
    "            'quarter': forecast['quarter'],\n",
    "            'model_price': forecast['forecast_price'],\n",
    "            'confidence': forecast['confidence'],\n",
    "            'days_ahead': forecast['days_ahead']\n",
    "        }\n",
    "        \n",
    "        # Try to find matching ICE futures\n",
    "        ice_match = None\n",
    "        if futures_comparison_data is not None:\n",
    "            matching_ice = futures_comparison_data[futures_comparison_data['comparison_quarter'] == forecast['quarter']]\n",
    "            if len(matching_ice) > 0:\n",
    "                ice_match = matching_ice.iloc[0]\n",
    "        \n",
    "        if ice_match is not None:\n",
    "            # Has ICE futures comparison\n",
    "            comparison_entry['ice_price'] = ice_match['ice_futures']\n",
    "            comparison_entry['difference_pct'] = ice_match['price_difference_pct']\n",
    "            comparison_entry['ice_data_available'] = True\n",
    "            # Use the same action logic\n",
    "            diff_pct = ice_match['price_difference_pct']\n",
    "            comparison_entry['action'] = 'BUY_ICE_SELL_MODEL' if diff_pct > 5 else 'BUY_MODEL_SELL_ICE' if diff_pct < -5 else 'HOLD'\n",
    "        else:\n",
    "            # No ICE futures available for this quarter\n",
    "            comparison_entry['ice_price'] = None\n",
    "            comparison_entry['difference_pct'] = None\n",
    "            comparison_entry['ice_data_available'] = False\n",
    "            comparison_entry['action'] = 'MODEL_ONLY_NO_ICE'\n",
    "        \n",
    "        all_comparisons.append(comparison_entry)\n",
    "    \n",
    "    # Add the comprehensive comparison to export data\n",
    "    export_data['comprehensive_comparison'] = all_comparisons\n",
    "    \n",
    "    # Also keep the original futures comparison for reference\n",
    "    if futures_comparison_data is not None and len(futures_comparison_data) > 0:\n",
    "        export_data['futures_comparison'] = {\n",
    "            'total_comparisons': len(futures_comparison_data),\n",
    "            'price_difference_summary': {\n",
    "                'average_difference_pct': float(futures_comparison_data['price_difference_pct'].mean()),\n",
    "                'max_positive_difference_pct': float(futures_comparison_data['price_difference_pct'].max()),\n",
    "                'max_negative_difference_pct': float(futures_comparison_data['price_difference_pct'].min()),\n",
    "                'average_absolute_difference_pct': float(futures_comparison_data['price_difference_pct'].abs().mean())\n",
    "            },\n",
    "            'detailed_comparisons': futures_comparison_data.to_dict('records')\n",
    "        }\n",
    "    \n",
    "    # Add trading insights based on comprehensive comparison\n",
    "    comparisons_with_ice = [c for c in all_comparisons if c['ice_data_available']]\n",
    "    if comparisons_with_ice:\n",
    "        above_ice = len([c for c in comparisons_with_ice if c.get('difference_pct', 0) > 0])\n",
    "        below_ice = len([c for c in comparisons_with_ice if c.get('difference_pct', 0) < 0])\n",
    "        \n",
    "        export_data['trading_insights'] = {\n",
    "            'total_quarters_with_ice_data': len(comparisons_with_ice),\n",
    "            'total_quarters_model_only': len([c for c in all_comparisons if not c['ice_data_available']]),\n",
    "            'model_above_ice_count': above_ice,\n",
    "            'model_below_ice_count': below_ice,\n",
    "            'model_above_ice_percentage': float(above_ice / len(comparisons_with_ice) * 100) if comparisons_with_ice else 0,\n",
    "            'arbitrage_opportunities': [\n",
    "                {\n",
    "                    'quarter': comp['quarter'],\n",
    "                    'model_price': comp['model_price'],\n",
    "                    'ice_price': comp['ice_price'],\n",
    "                    'difference_pct': comp['difference_pct'],\n",
    "                    'action': comp['action']\n",
    "                }\n",
    "                for comp in comparisons_with_ice if comp['action'] != 'HOLD'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(export_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Forecast results exported to {output_path}\")\n",
    "    \n",
    "    # Also create CSV files for easy analysis\n",
    "    try:\n",
    "        # Quarterly forecasts CSV\n",
    "        forecasts_df = pd.DataFrame(quarterly_forecasts_data)\n",
    "        forecasts_df.to_csv(\"quarterly_forecasts_detailed.csv\", index=False)\n",
    "        print(\"‚úÖ CSV: quarterly_forecasts_detailed.csv\")\n",
    "        \n",
    "        # Comprehensive comparison CSV\n",
    "        comp_df = pd.DataFrame(all_comparisons)\n",
    "        comp_df.to_csv(\"comprehensive_comparison.csv\", index=False)\n",
    "        print(\"‚úÖ CSV: comprehensive_comparison.csv\")\n",
    "        \n",
    "        # Summary CSV\n",
    "        summary_data = []\n",
    "        for forecast in quarterly_forecasts_data:\n",
    "            summary_row = {\n",
    "                'quarter': forecast['quarter'],\n",
    "                'date': forecast['date'],\n",
    "                'model_forecast': forecast['forecast_price'],\n",
    "                'confidence': forecast['confidence'],\n",
    "                'days_ahead': forecast['days_ahead']\n",
    "            }\n",
    "            \n",
    "            # Add ICE comparison if available\n",
    "            matching_comp = next((c for c in all_comparisons if c['quarter'] == forecast['quarter']), None)\n",
    "            if matching_comp and matching_comp['ice_data_available']:\n",
    "                summary_row['ice_futures'] = matching_comp['ice_price']\n",
    "                summary_row['price_difference_pct'] = matching_comp['difference_pct']\n",
    "                summary_row['action'] = matching_comp['action']\n",
    "            else:\n",
    "                summary_row['ice_futures'] = None\n",
    "                summary_row['price_difference_pct'] = None\n",
    "                summary_row['action'] = 'MODEL_ONLY'\n",
    "            \n",
    "            summary_data.append(summary_row)\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(\"forecast_summary.csv\", index=False)\n",
    "        print(\"‚úÖ CSV: forecast_summary.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create CSV files: {e}\")\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Choose which forecasts to export\n",
    "if 'quarterly_forecasts_improved' in locals() and len(quarterly_forecasts_improved) > 0:\n",
    "    forecasts_to_export = quarterly_forecasts_improved\n",
    "    comparison_to_export = futures_comparison_improved if 'futures_comparison_improved' in locals() else None\n",
    "    print(\"üìä Using IMPROVED forecasts for export\")\n",
    "elif 'quarterly_forecasts_complete' in locals() and len(quarterly_forecasts_complete) > 0:\n",
    "    forecasts_to_export = quarterly_forecasts_complete\n",
    "    comparison_to_export = futures_comparison if 'futures_comparison' in locals() else None\n",
    "    print(\"üìä Using COMPLETE forecasts for export\")\n",
    "else:\n",
    "    print(\"‚ùå No forecast data found for export\")\n",
    "    forecasts_to_export = []\n",
    "    comparison_to_export = None\n",
    "\n",
    "# Export the results\n",
    "if len(forecasts_to_export) > 0:\n",
    "    export_results = export_forecast_results(\n",
    "        forecasts_to_export, \n",
    "        comparison_to_export\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä EXPORT SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ JSON file: sugar_forecasts_2026_2027.json\")\n",
    "    print(f\"   ‚Ä¢ Forecasts: {len(forecasts_to_export)} quarterly forecasts\")\n",
    "    print(f\"   ‚Ä¢ Quarters with ICE data: {len([f for f in export_results['comprehensive_comparison'] if f['ice_data_available']])}\")\n",
    "    print(f\"   ‚Ä¢ Model-only quarters: {len([f for f in export_results['comprehensive_comparison'] if not f['ice_data_available']])}\")\n",
    "    print(f\"   ‚Ä¢ Average confidence: {np.mean([f['confidence'] for f in forecasts_to_export]):.1%}\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for export\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
